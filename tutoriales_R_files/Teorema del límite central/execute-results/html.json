{
  "hash": "7c3e16bf01048ef2a698a697c9a7c942",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Teorema del límite central\"\ndate: today\nformat:\n  html:\n    toc: true\n    collapse-sections: true\nexecute:\n  warning: false\n  message: false\n---\n\n# Librerías\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(scales)\nlibrary(BSDA)\nlibrary(samplingbook)\nlibrary(EnvStats)\nlibrary(pwr)\nlibrary(car)\n```\n:::\n\n\n# Distribución muestral\n\nLa idea básica que se sigue es que un estadístico muestral es también una **variable aleatoria**, entonces ese estadístico posee una distribución. Por tanto:\n\n> La distribución de un estadístico muestral recibe el nombre de distribución muestral o distribución de la muestra. La distribución muestral en la distribción de muestras que pertenecen a la misma población.\n\nPor ejemplo:\n\n*Supongamos que queremos estimar la altura media de los estudiantes de una universidad. Para ello, tomamos una muestra aleatoria de 50 estudiantes y calculamos su altura media. Repetimos este proceso muchas veces, tomando muestras aleatorias de 50 estudiantes cada vez y calculando la altura media de cada muestra. La distribución de todas estas medias muestrales es la distribución muestral de la media de altura de los estudiantes de la universidad.*\n\n## Distribución muestral de la media\n\nSupongamos que la muestra aleatoria proviene de una población normal.\n\nDicha distribución tiene unos parámetros $\\mu$ y $\\sigma$, que son poblacionales. Siendo $X_1, \\cdots, X_n$ una muestra **aleatoria** que proviene de dicha población tendrá parámetros conocidos o desconocidos $\\bar{x}$ y $s$.\n\nPor ejemplo, tomemos una distribución normal con $\\mu = 5$ y $\\sigma = 2$\n\n$$\nx \\sim N(5, 2)\n$$ \n\nCambiemos gradualmente el tamaño de muestra y observemos el comportamiento del tamaño de la muestra sobre el parámetro muestral. Veamos como al aumentar N, la media de la muestra se vuelve más cercana a 5.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndatos <- 2:2000 %>% \n  purrr::map_dfr(function(N){\n    \n    \n    muestra <- rnorm(N, 5, 2)\n    \n    data.frame(N, Media = mean(muestra), Var = var(muestra))\n    \n    \n  }) \n\ndatos %>% \n  ggplot2::ggplot(aes(x = N, y = Media)) +\n  geom_line() +\n  geom_hline(yintercept = 5, color = \"#331114\") +\n  labs(title = \"Efecto del tamaño de muestra\",\n       subtitle = \"Media\") +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](Teorema-del-límite-central_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\nSi la muestra proviene de poblaciones no normales o desconocidas, se puede aplicar el Teorema del Límite Central (**TLC**).\n\n## Distribución muestral de la varianza\n\nSe sigue de igual forma que con la sección anterior.\n\n¿Por qué el intercepto en este gráfico es 4 y no 2? Si la variable aleatoria es $x \\sim N(5, 2)$.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndatos %>% \n  ggplot2::ggplot(aes(x = N, y = Var)) +\n  geom_line() +\n  geom_hline(yintercept = 4, color = \"#331114\") +\n  labs(title = \"Efecto del tamaño de muestra\",\n       subtitle = \"Varianza\") +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](Teorema-del-límite-central_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\n# Ley de los grandes números\n\nYa fue demostrado en los ejemplos anteriores, indica que son conocidos aquellos resultados del cálculo de probabilidades sobre la estabilidad a largo plazo de una variable aleatoria.\n\nFormalmente, se refiere a una sucesión de variables aleatorias independientes e idénticamente distribuidas con varianza finita, y asegura que el promedio de las $n$ primeras observaciones (variables aleatorias) se acerca a la media teórica cuando el número $n$ de repeticiones tiende hacia infinito.\n\n### Ley débil\n\n$$\n\\lim_{n \\to \\infty}\\left(1 - \\frac{\\sigma^2}{n\\varepsilon^2} \\right) = 1\n$$\n\nEstablece que se puede encontrar un tamaño de muestra $n$ que garantice con una probabilidad tan cercana a uno como se quiera, que el promedio que se obtendría en esa muestra, no difiera del promedio poblacional en menos de una cantidad tan pequeña como se desee $\\varepsilon$.\n\nPor ejemplo: para una población con media desconocida y $\\sigma = 2$, se desea determinar el tamaño de muestra que garantice un probabilidad de al menos 0.95 de que la media muestral que se calcularía en esa muestra no se aleje de $\\mu$ en 0.5.\n\n$$\n1 - \\frac{\\sigma^2}{n\\varepsilon^2} = 0.95 \\\\\n\\left((1-0.95)*\\frac{\\varepsilon^2}{\\sigma^2}\\right)^{-1}=n \\\\\n\\left(0.05*\\frac{0.5^2}{2^2}\\right)^{-1} = 320 = n\n$$\n\nVeamos esto en el gráfico anterior de la media\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndatos %>% \n  ggplot2::ggplot(aes(x = N, y = Media)) +\n  geom_line() +\n  geom_hline(yintercept = 5, color = \"#331114\") +\n  geom_vline(xintercept = 320, color = \"#9BA1AB\", \n             linewidth = 1.5, linetype = 4) + \n  scale_y_continuous(breaks = scales::extended_breaks(20)) +\n  scale_x_continuous(breaks = scales::extended_breaks(10)) +\n  labs(title = \"Efecto del tamaño de muestra\",\n       subtitle = \"Media\") +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](Teorema-del-límite-central_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\n### Ley fuerte\n\nLa frecuencia relativa con que ocurre un hecho en pruebas independientes y en las mismas condiciones converge a la probabilidad del hecho observado con probabilidad 1. Su demostración excede el alcance de este recurso.\n\n# Teorema del límite central (TLC)\n\nLa distribución normal se puede usar frecuentemente para aproximar las distribuciones de **otras variables aleatorias**, como consecuencia del Teorema del Límite Central (TLC).\n\nEl TLC dice, *de manera simplificada*, que la distribución de las medias muestrales (aleatorias e independientes) sigue una distribución normal, siempre que el tamaño de las muestras sea lo suficientemente grande.\n\n> Nota: quizá en otros cursos o incluso en literatura desactualizada se le indique que este tamaño de muestra \"lo suficientemente grande\" es 30, pero eso es una regla de \"dedo\" que hoy en día no tiene mucho fundamento.\n\n*Hagamos una demostración de lo que se indica en la nota*.\n\n1.  Generemos una distribución asimétrica\n\n$$\nx \\sim LN(0, 1)\n$$\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndist_asimetrica <- data.frame(x = rlnorm(5000))\n\ndist_asimetrica %>% \n  ggplot2::ggplot(aes(x)) + \n  geom_histogram(bins = 13, color = \"#9BA1AB\", fill =  \"#331114\") +\n  labs(title = \"Distribución asimétrica\",\n       subtitle = \"Lognormal estándar\",\n       y = \"Frecuencia\") +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](Teorema-del-límite-central_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\n2.  Tomemos 1000 muestras de tamaño $n = 30$ y calculemos el promedio de cada muestra y hagamos un histograma. En buena teoría, con ese tamaño de muestra la distribución generada debería ser normal\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# set.seed(456)\n\nmuestras <- 1:1000 %>% \n  purrr::map_dbl(function(m){\n    \n    media <- dist_asimetrica %>% \n      dplyr::slice_sample(n = 30) %>% \n      dplyr::pull(x) %>% \n      mean()\n    \n    return(media)\n    \n  })\n\n# Generación del histograma -----\n\ndata.frame(muestras = muestras) %>% \n  ggplot2::ggplot(aes(muestras)) + \n  geom_histogram(bins = 11, color = \"#9BA1AB\", \n                 fill =  \"#331114\") +\n  labs(title = \"Incumplimiento del TLC\",\n       y = \"Frecuencia\") +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](Teorema-del-límite-central_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\n> **No** se ve con forma de campana centrada, ¿verdad? Entonces, ¿por qué no se cumplió el TLC? \n\nAhora hagamos una prueba formal.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Prueba formal  -------\n\nnortest::ad.test(muestras)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tAnderson-Darling normality test\n\ndata:  muestras\nA = 9.3847, p-value < 2.2e-16\n```\n\n\n:::\n\n```{.r .cell-code}\ncar::qqPlot(muestras,\n            main = \"Gráfico de cuantil-cuantil (Q-Q plot)\",\n                 ylab = \"Distribución\",\n                 xlab = \"Cuantiles teóricos (normales)\",\n                 col.lines = \"#331114\")\n```\n\n::: {.cell-output-display}\n![](Teorema-del-límite-central_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 617 701\n```\n\n\n:::\n:::\n\n\n> En resumen, un tamaño de 30 no fue adecuado, no se cumplió el TLC. Por tanto esa regla no es una verdad inamovible, es una sugerencia qué **puede** ser válida en la mayoría de ocasiones. \n\nContinuando con el TCL, bajo condiciones bastante generales, las sumas y las medias de muestras de observaciones aleatorias extraídas de una población tienden a poseer, aproximadamente, una distribución acampanada cuando se repite el muestreo muchas veces.\n\nEn teoría esa distribución estará definida por la misma media que la poblacional y con una desviación típica igual al cociente entre la desviación típica poblacional dividida por la raíz cuadrada del tamaño de muestra (o la varianza poblacional dividida entre el tamaño de muestra).\n\n$$\n\\bar{X} \\sim N\\left(\\mu, \\frac{\\sigma}{\\sqrt{n}}\\right)\n$$\n\n## Ejemplo 01\n\nSupongamos un experimento de lanzamiento de dados, cada cara está igual de cargada, por lo que la probabilidad de obtener cualquier cara es de 1/6.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# así sería lanzar el dado 5 veces\n\nsample((1:6), # valores posibles (las caras del dado)\n       5, # cantidad de lanzamientos\n       replace = TRUE, # puede salir el mismo valor varias veces\n       prob = rep(1/6, 6)) # probabilidad para valor de las caras del dado\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1 3 1 1 6\n```\n\n\n:::\n:::\n\n\nAhora, repitamos el lanzamiento, 5000 veces y observemos la distribución de los datos, la frecuencia relativa de cada lanzamiento debería ser **aproximadamente** 1/6 = 16.67 %.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlanzamientos <- sample(1:6, 5000, replace = TRUE, prob = rep(1/6, 6))\n\ntabla <- summarytools::freq(lanzamientos)\n\ndata.frame(tabla) %>% \n  tibble::rownames_to_column() %>% \n  dplyr::select(1:4) %>% \n  setNames(c(\"Valor del dado\", \"Frecuencia\", \"Frecuencia (%)\", \n             \"Frecuencia acumulada (%)\")) %>% \n  knitr::kable(format = \"html\") %>%\n  kableExtra::kable_styling()\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Valor del dado </th>\n   <th style=\"text-align:right;\"> Frecuencia </th>\n   <th style=\"text-align:right;\"> Frecuencia (%) </th>\n   <th style=\"text-align:right;\"> Frecuencia acumulada (%) </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> 1 </td>\n   <td style=\"text-align:right;\"> 834 </td>\n   <td style=\"text-align:right;\"> 16.68 </td>\n   <td style=\"text-align:right;\"> 16.68 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 2 </td>\n   <td style=\"text-align:right;\"> 863 </td>\n   <td style=\"text-align:right;\"> 17.26 </td>\n   <td style=\"text-align:right;\"> 33.94 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 3 </td>\n   <td style=\"text-align:right;\"> 817 </td>\n   <td style=\"text-align:right;\"> 16.34 </td>\n   <td style=\"text-align:right;\"> 50.28 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 4 </td>\n   <td style=\"text-align:right;\"> 819 </td>\n   <td style=\"text-align:right;\"> 16.38 </td>\n   <td style=\"text-align:right;\"> 66.66 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 5 </td>\n   <td style=\"text-align:right;\"> 865 </td>\n   <td style=\"text-align:right;\"> 17.30 </td>\n   <td style=\"text-align:right;\"> 83.96 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 6 </td>\n   <td style=\"text-align:right;\"> 802 </td>\n   <td style=\"text-align:right;\"> 16.04 </td>\n   <td style=\"text-align:right;\"> 100.00 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> &lt;NA&gt; </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> NA </td>\n   <td style=\"text-align:right;\"> NA </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Total </td>\n   <td style=\"text-align:right;\"> 5000 </td>\n   <td style=\"text-align:right;\"> 100.00 </td>\n   <td style=\"text-align:right;\"> 100.00 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\nEsto quiere decir que la distribución de los datos es uniforme discreta (ojo que no continua). Por lo que la cantidad de veces que se va a obtener una cara es:\n\n$$\nFrecuencia = \\frac{1}{6}\\cdot 5000 = 833.33\n$$\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata.frame(lanzamientos) %>% \n  ggplot2::ggplot(aes(lanzamientos)) + \n  geom_bar(fill = \"#331114\") +\n  geom_hline(yintercept = 833.33, size = 2, color = \"#9BA1AB\") +\n  scale_x_continuous(breaks = 1:6) +\n  labs(x = \"Lanzamientos\", \n       y = \"Frecuencia\") +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](Teorema-del-límite-central_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\nAhora expandamos el experimento, supongamos que vamos a extraer una muestra de $n=5$ observaciones de la población anterior (el lanzamiento de un dado) y que se muestreo se repite en 1000 ocasiones. Para cada una de esas 5 observaciones se obtiene la media.\n\nSiguiendo el TLC, la forma resultante de este muestreo es la de una campana de Gauss (aproximadamente).\n\nPor ejemplo:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# comencemos por hacer el experimento 10 veces\n\nfor(i in 1:10){\n  \n  dado <- sample(1:6, 5, # lanzar 5 veces\n                 replace = TRUE, prob = rep(1/6, 6))\n  \n  print(mean(dado)) # calcular la media\n  \n}\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 3.2\n[1] 3.4\n[1] 3.2\n[1] 3\n[1] 2.6\n[1] 2.4\n[1] 4.2\n[1] 3.6\n[1] 3.4\n[1] 2.6\n```\n\n\n:::\n:::\n\n\nAhora si, repitámoslo 1000 veces\n\n\n::: {.cell}\n\n```{.r .cell-code}\nexperimento_dado <- data.frame() # data frame vacío\n\nfor(i in 1:1000){\n  \n  dado <- sample(1:6, 5, # lanzar 5 veces\n                 replace = TRUE, prob = rep(1/6, 6))\n  \n  experimento_dado[i, 1] <- mean(dado) # rellenamos el data frame\n  \n}\n\n# Y ahora observemos si toma forma de campana.\n\n\nhist(experimento_dado$V1,\n     main = \"Experimento 01: Media de 5 lanzamientos de dado, 1000 veces\",\n     xlab = \"Media de 5 lanzamientos\",\n     ylab = \"Frecuencia\",\n     col = \"#331114\", \n     border = \"#9BA1AB\")\n```\n\n::: {.cell-output-display}\n![](Teorema-del-límite-central_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\n> ¿Cuál es la media de los datos del experimento?\n\nSe sabe, que la media (esperanza matemática de un dado) es 3.5. La media del experimento generado, debería ser aproximadamente igual.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmean(experimento_dado$V1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 3.531\n```\n\n\n:::\n:::\n\n\n> ¿Cuál es la varianza de los datos del experimento?\n\nSe sabe, que para un dado perfecto, la varianza es:\n\n$$\n\\frac{1}{6}\\cdot\\sum_{i=1}^6 (x_i - 3.5)^2 = 2.92\n$$\n\nY por tanto la desviación es: 1.71. Siguiendo la fórmula anterior:\n\n$$\n\\frac{\\sigma}{\\sqrt{n}} = \\frac{1.71}{\\sqrt{5}} = 0.765\n$$\n\nLa desviación estándar del experimento debería ser aproximadamente similar:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsd(experimento_dado$V1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.7782317\n```\n\n\n:::\n:::\n\n\n> Finalmente\n\nAunque la distribución de la población es uniforme discreta, vemos como la de las medias muestrales se asemeja a una distribución normal.\n\nEn una situación real tendríamos sólo los estadísticos de nuestra muestra:\n\n$$\n\\bar{X} \\sim N(3.531, 0.7782317)\n$$\n\nGracias a TLC podemos acercarnos a conocer las características de la población, mediante la toma de muestras.\n\nPor ejemplo, la media poblacional y la media muestral son similares. La desviación poblacional $\\sigma$ puede obtenerse al despejar esta fórmula $\\frac{\\sigma}{\\sqrt{n}} = s$.\n\n> ¿Qué pasa si se aumenta $n$?\n\nLa aproximación se hace más precisa.\n\n> Finalmente\n\n$$\nZ = \\frac{\\bar{X}-\\mu}{\\frac{\\sigma}{\\sqrt{n}}}\n$$\n\n",
    "supporting": [
      "Teorema-del-límite-central_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}