---
title: "Pruebas de bondad de ajuste para distribuciones"
subtitle: "[Versi√≥n PDF](https://stevenggoni.github.io/clases/II-1123_02_Bondad_ajuste.pdf) <br> II-1123 Estad√≠stica para Ingenier√≠a Industrial II"
date: today
format: revealjs
---

```{r}

library(tidyverse)
library(plotly)

```

## Agenda {.bloques}

-   Preguntas generadoras
-   Concepto de bondad de ajuste
-   Rutinas gr√°ficas
-   Test de $\chi^2$
-   Pruebas de normalidad
-   Otras rutinas de identificaci√≥n de distribuciones

## Preguntas generadoras {.bloques}

-   ¬øC√≥mo se selecicona la distribuci√≥n que mejor se ajusta a los datos?

-   ¬øPor qu√© es necesario conocer qu√© distribuci√≥n se ajusta a los datos?

## ¬øQu√© es bondad de ajuste? {.bloques}

-   Es el grado de acoplamiento que existe entre los datos originales y los valores te√≥ricos.
-   Describe que tan bien se ajusta un conjunto de observaciones. Tales medidas, por lo general, describen o resumen la discrepancia entre los valores observados y los valores esperados en el modelo de estudio.
-   Para ello se emplean contrastes de hip√≥tesis.
-   La bondad de ajuste es un concepto estad√≠stico que mide qu√© tan bien un conjunto de [datos observados]{.hi} se ajusta a una distribuci√≥n de [probabilidad te√≥rica]{.hi} espec√≠fica.
-   En otras palabras, eval√∫a si los datos podr√≠an razonablemente provenir de una distribuci√≥n determinada (por ejemplo, binomial, Poisson, normal, exponencial, etc.).

## Rutinas gr√°ficas {.bloques}

-   Se usan como herramienta para la identificaci√≥n de distribuciones.

-   Son [procedimientos visuales]{.hi} que se usan para comparar los datos observados en una distribuci√≥n te√≥rica, con el fin de evaluar de [forma preliminar]{.hi} si el modelo propuesto parece adecuado.

-   No sustituyen bajo ning√∫n concepto a las pruebas formales que van a ser estudiadas, pero permiten detectar patrones de desviaci√≥n, asimetr√≠as o valores at√≠picos antes de aplicar dichas pruebas.

-   Su ventaja principal es que la [vista humana es muy sensible para reconocer discrepancias]{.hi} que podr√≠an pasar desapercibidas en un solo estad√≠stico num√©rico.

## Recuerde: Visualizaci√≥n {.bloques style="font-size: 1.2em;"}

-   Una buena visualizaci√≥n mostrar√° cosas que no se esperaban o har√° surgir nuevas preguntas acerca de los datos. Tambi√©n puede dar pistas acerca de si se est√°n haciendo las preguntas equivocadas o si necesitas recolectar datos diferentes.

-   [‚ÄúUn simple gr√°fico ha brindado m√°s informaci√≥n a la mente del analista de datos que cualquier otro dispositivo‚Äù]{.hi} - *John Tukey*

## Rutinas gr√°ficas: Formalmente {.bloques style="font-size: 1.2em;"}

-   Una rutina gr√°fica es un [conjunto de pasos estandarizados]{.hi} para elaborar y analizar gr√°ficamente la relaci√≥n entre los datos observados y una distribuci√≥n te√≥rica, de manera que se pueda evaluar visualmente la concordancia antes de realizar pruebas formales.

## ¬øCu√°les gr√°ficos usar? {.bloques}

:::::: columns
::: {.column width="35%"}
### Variable continua

```{r}

set.seed(123)

n <- 500

datos_w <- data.frame(Datos = rweibull(n, 2, 2))


g1 <- datos_w %>% 
  ggplot(aes(Datos, y=after_stat(density))) +
  geom_histogram(bins = round(1 + log2(n)), 
                 fill = "#263247", 
                 color = "#C18A00") +
  geom_density(color = "#C18A00", linetype="dashed", linewidth=1) +
  labs(y = "Densidad") +
  theme_bw()

plotly::ggplotly(g1, height = 600, width = 550) %>% 
  plotly::layout(paper_bgcolor = "#F1F5F5",
                 plot_bgcolor  = "#F1F5F5",
                 font = list(size = 30),
                 xaxis = list(
                   title = list( font = list(size = 30)),
                   tickfont = list(size = 25)),
                 yaxis = list(title = list(font = list(size = 30)),
                              tickfont = list(size = 25)))

```
:::

::: {.column width="30%" style="font-size: 0.90em;"}
-   Histograma (variables continuas)
    -   Puede agregar una ‚Äúcurva‚Äù te√≥rica superpuesta para evaluar el ajuste.
-   Gr√°fico de barras (Variables discretas)
    -   Puede agregar puntos t√©oricos que le permitan evaluar el ajuste.
:::

::: {.column width="35%"}
### Variable discreta

```{r}

datos_b <- data.frame(Datos = rbinom(n, 5, 0.4))

g2 <- datos_b %>% 
  dplyr::count(Datos) %>% 
  dplyr::mutate(Masa = dbinom(0:5, 5, 0.4)) %>% 
  ggplot(aes(x = Datos, y = n/500)) +
  geom_col(fill = "#263247") +
  geom_point(aes(y = Masa), color = "#C18A00", size = 4) +
  labs(y = "Masa") +
  theme_bw()

plotly::ggplotly(g2, height = 600, width = 550) %>% 
  plotly::layout(paper_bgcolor = "#F1F5F5",
                 plot_bgcolor  = "#F1F5F5",
                 font = list(size = 30),
                 xaxis = list(
                   title = list( font = list(size = 30)),
                   tickfont = list(size = 25)),
                 yaxis = list(title = list(font = list(size = 30)),
                              tickfont = list(size = 25)))

```
:::
::::::

## ¬øCu√°les gr√°ficos usar? {.bloques}

:::::: columns
::: {.column width="28%" style="font-size: 0.88em;"}
-   Puede usar un gr√°fico de probabilidad ([Probability plot]{.hi}) o un gr√°fico cuantil-cuantil ([QQ Plot]{.hi}).

    -   La idea que sigue este gr√°fico es que si los puntos se alinean a una recta (te√≥rica), el ajuste es plausible, mientras que si hay desviaciones sistem√°ticas habr√≠a indicativos de mala concordancia.
:::

::: {.column width="36%"}
### No normal

Estos datos se desv√≠an mucho de la distribuci√≥n te√≥rica [normal]{.hi}, lo que es indicativo de que no siguen la distribuci√≥n normal.

```{r}

## Bandas de confianza intervalos

sim_matrix <- replicate(1000, # n√∫mero de simulaciones
                        {sort(rnorm(n, mean = 1.77, sd = 0.89))})

lower <- apply(sim_matrix, 1, quantile, probs = 0.025)
upper <- apply(sim_matrix, 1, quantile, probs = 0.975)

```

```{r}

theoretical <- qnorm(ppoints(n))

sample_q <- sort(datos_w$Datos)

fit <- lm(sample_q ~ theoretical)

plot_ly(height = 400, width = 550) %>%
  plotly::add_ribbons(x = theoretical,
                      ymin = lower,
                      ymax = upper,
                      fillcolor = "rgba(38,50,71,0.15)",
                      line = list(color = "transparent"),
                      showlegend = FALSE) %>% 
  plotly::add_markers(x = theoretical,
                      y = sample_q,
                      marker = list(color = "#C18A00"),
                      showlegend = FALSE) %>%
  plotly::add_lines(x = theoretical,
                    y = fitted(fit),
                    line = list(color = "#263247"),
                    showlegend = FALSE) %>%
  plotly::layout(paper_bgcolor = "#F1F5F5",
                 plot_bgcolor  = "#F1F5F5",
                 font = list(size = 25),
                 xaxis = list(
                   title = list(text = "Cuantiles te√≥ricos normales",
                                font = list(size = 25)),
                   tickfont = list(size = 20)),
                 yaxis = list(title = list(text = "Distribuci√≥n NO normal",
                                           font = list(size = 25)),
                              tickfont = list(size = 20)))

```
:::

::: {.column width="36%"}
### Normal

Los puntos [siguen la l√≠nea te√≥rica]{.hi}, lo que es indicativo que en este caso se sigue la distribuci√≥n normal.

```{r}

## Bandas de confianza intervalos

sim_matrix <- replicate(1000, # n√∫mero de simulaciones
                        {sort(rnorm(n, mean = 0, sd = 1))})

lower <- apply(sim_matrix, 1, quantile, probs = 0.025)
upper <- apply(sim_matrix, 1, quantile, probs = 0.975)

```

```{r}

x2 <- rnorm(n)
theoretical2 <- qnorm(ppoints(n))
sample_q2 <- sort(x2)
fit2 <- lm(sample_q2 ~ theoretical2)

plotly::plot_ly(height = 400, width = 550) %>%
  plotly::add_ribbons(x = theoretical2,
                      ymin = lower,
                      ymax = upper,
                      fillcolor = "rgba(38,50,71,0.15)",
                      line = list(color = "transparent"),
                      showlegend = FALSE) %>% 
  plotly::add_markers(x = theoretical2,
                      y = sample_q2,
                      marker = list(color = "#C18A00"),
                      showlegend = FALSE) %>%
  plotly::add_lines(x = theoretical2,
                    y = fitted(fit2),
                    line = list(color = "#263247"),
                    showlegend = FALSE) %>%
  plotly::layout(paper_bgcolor = "#F1F5F5",
                 plot_bgcolor  = "#F1F5F5",
                 font = list(size = 30),
                 xaxis = list(
                   title = list(text = "Cuantiles te√≥ricos normales",
                                font = list(size = 30)),
                   tickfont = list(size = 25)),
                 yaxis = list(title = list(text = "Distribuci√≥n normal",
                                           font = list(size = 30)),
                              tickfont = list(size = 25)))


```
:::
::::::

## ¬øCu√°les gr√°ficos usar? {.bloques}

::::: columns
::: {.column width="50%"}
-   El gr√°fico de probabilidad o el gr√°fico de cuantil ‚Äì cuantil a menudo es ‚Äúrecetado‚Äù para una distribuci√≥n normal, pero [se puede usar para cualquier distribuci√≥n]{.hi} siempre que se conozcan los cuantiles te√≥ricos.

-   Por ejemplo, en este caso, de una Weibull(2,2), que son los datos que dieron origen a la "Distribuci√≥n no normal" del slide anterior, que al ser probada contra una normal, no se ajust√≥ correctamente. Caso contrario al observado a la derecha.
:::

::: {.column width="50%"}
### QQ-Plot (Weibull)

```{r}

## Bandas de confianza intervalos

sim_matrix <- replicate(1000, # n√∫mero de simulaciones
                        {sort(rweibull(n, shape = 2, scale =  2))})

lower <- apply(sim_matrix, 1, quantile, probs = 0.025)
upper <- apply(sim_matrix, 1, quantile, probs = 0.975)

```

```{r}

p <- ppoints(n)

theoretical_w <- qweibull(p, shape = 2, scale = 2)

sample_q <- sort(datos_w$Datos)

fit <- lm(sample_q ~ theoretical_w)

plotly::plot_ly(height = 600, width = 850) %>%
  plotly::add_ribbons(x = theoretical_w,
                      ymin = lower,
                      ymax = upper,
                      fillcolor = "rgba(38,50,71,0.15)",
                      line = list(color = "transparent"),
                      showlegend = FALSE) %>% 
  plotly::add_markers(x = theoretical_w,
                      y = sample_q,
                      marker = list(color = "#C18A00"),
                      showlegend = FALSE) %>%
  plotly::add_lines(x = theoretical_w,
                    y = fitted(fit),
                    line = list(color = "#263247"),
                    showlegend = FALSE) %>%
  plotly::layout(paper_bgcolor = "#F1F5F5",
                 plot_bgcolor  = "#F1F5F5",
                 font = list(size = 25),
                 xaxis = list(
                   title = list(text = "Cuantiles te√≥ricos Weibull (2,2)",
                                font = list(size = 25)),
                   tickfont = list(size = 20)),
                 yaxis = list(title = list(text = "Distribuci√≥n Weibull",
                                           font = list(size = 25)),
                              tickfont = list(size = 20)))

```
:::
:::::

## Improtancia de la visualizaci√≥n {.bloques}

::::: columns
::: {.column width="70%"}
-   Este tipo de gr√°ficos [se utilizan]{.hi} con frecuencia y de forma simult√°nea [con pruebas estad√≠sticas formales]{.hi} para contrastar la hip√≥tesis de que un dato siga una distribuci√≥n particular.

-   Tambi√©n es relevante para saber que tipo de prueba de hip√≥tesis realizar.

-   ¬øTiene sentido aplicarle una prueba de normalidad a estos datos?

    -   No ¬øverdad?

-   En este caso resultar√≠a conveniente aplicar una prueba [apropiada para la forma de los datos]{.hi}, por ejemplo, podemos intuir estas dos:

    -   Lognormal
    -   Exponencial
:::

::: {.column width="30%"}
### Distribuci√≥n asim√©trica

```{r}

set.seed(123)

datos_e <- data.frame(Datos = rexp(n, 2))

g3 <- datos_e %>% 
  ggplot(aes(Datos, y = after_stat(density))) +
  geom_histogram(bins = round(1 + log2(n)), 
                 fill = "#263247", 
                 color = "#C18A00") +
  geom_density(color = "#C18A00", linetype="dashed", linewidth=1) +
  labs(y = "Densidad") +
  theme_bw()

plotly::ggplotly(g3, height = 600, width = 500) %>% 
  plotly::layout(paper_bgcolor = "#F1F5F5",
                 plot_bgcolor  = "#F1F5F5",
                 font = list(size = 30),
                 xaxis = list(
                   title = list( font = list(size = 30)),
                   tickfont = list(size = 25)),
                 yaxis = list(title = list(font = list(size = 30)),
                              tickfont = list(size = 25)))

```
:::
:::::

## Improtancia de la visualizaci√≥n {.bloques}

:::::: columns
::: {.column width="24%"}
-   Como es obvio, la normal [no es una buena opci√≥n]{.hi}, por lo que no se debe ni intentar.
-   Y entre la *lognormal* y *exponencial*, esta √∫ltima resulta con mejor ajuste.
:::

::: {.column width="38%"}
### QQ-plot (exponencial)

```{r}

## Bandas de confianza intervalos

sim_matrix <- replicate(1000, # n√∫mero de simulaciones
                        {sort(rexp(n, 2))})

lower <- apply(sim_matrix, 1, quantile, probs = 0.025)
upper <- apply(sim_matrix, 1, quantile, probs = 0.975)

```

```{r}

p <- ppoints(n)

theoretical_e <- qexp(p, 2)

sample_q <- sort(datos_e$Datos)

fit <- lm(sample_q ~ theoretical_e)

plotly::plot_ly(height = 600, width = 650) %>%
  plotly::add_ribbons(x = theoretical_e,
                      ymin = lower,
                      ymax = upper,
                      fillcolor = "rgba(38,50,71,0.15)",
                      line = list(color = "transparent"),
                      showlegend = FALSE) %>% 
  plotly::add_markers(x = theoretical_e,
                      y = sample_q,
                      marker = list(color = "#C18A00"),
                      showlegend = FALSE) %>%
  plotly::add_lines(x = theoretical_e,
                    y = fitted(fit),
                    line = list(color = "#263247"),
                    showlegend = FALSE) %>%
  plotly::layout(paper_bgcolor = "#F1F5F5",
                 plot_bgcolor  = "#F1F5F5",
                 font = list(size = 25),
                 xaxis = list(
                   title = list(text = "Cuantiles te√≥ricos Exponencial(2)",
                                font = list(size = 25)),
                   tickfont = list(size = 20)),
                 yaxis = list(title = list(text = "Distribuci√≥n Exponencial",
                                           font = list(size = 25)),
                              tickfont = list(size = 20)))

```
:::

::: {.column width="38%"}
### QQ-plot (lognormal)

```{r}

## Bandas de confianza intervalos

sim_matrix <- replicate(1000, # n√∫mero de simulaciones
                        {sort(rlnorm(n, -1.24, 1.29))})

lower <- apply(sim_matrix, 1, quantile, probs = 0.025)
upper <- apply(sim_matrix, 1, quantile, probs = 0.975)

```

```{r}

p <- ppoints(n)

theoretical_ln <- qlnorm(p, meanlog = -1.24,  sdlog = 1.29)

sample_q <- sort(datos_e$Datos)

fit <- lm(sample_q ~ theoretical_ln)

plotly::plot_ly(height = 600, width = 650) %>%
  plotly::add_ribbons(x = theoretical_ln,
                      ymin = lower,
                      ymax = upper,
                      fillcolor = "rgba(38,50,71,0.15)",
                      line = list(color = "transparent"),
                      showlegend = FALSE) %>%
  plotly::add_markers(x = theoretical_ln,
                      y = sample_q,
                      marker = list(color = "#C18A00"),
                      showlegend = FALSE) %>%
  plotly::add_lines(x = theoretical_ln,
                    y = theoretical_ln,
                    line = list(color = "#263247"),
                    showlegend = FALSE) %>%
  plotly::layout(paper_bgcolor = "#F1F5F5",
                 plot_bgcolor  = "#F1F5F5",
                 font = list(size = 25),
                 xaxis = list(
                   title = list(text = "Cuantiles te√≥ricos Lognormal(-1.24, 1.29)",
                                font = list(size = 25)),
                   tickfont = list(size = 20)),
                 yaxis = list(title = list(text = "Distribuci√≥n Exponencial",
                                           font = list(size = 25)),
                              range = c(0, 5),
                              tickfont = list(size = 20)))

```
:::
::::::

## Recordemos antes de continuar {.bloques}

-   Hacer estad√≠stica [no es solo leer valores p de forma indiscriminada]{.hi}.
-   La comunidad cient√≠fica ha insistido en que evitemos la mala pr√°ctica de solo interpretar el valor P.
    -   [No perpetuemos este error]{.hi}.
-   Los valores P se analizan [en conjunto]{.hi} con los dem√°s estad√≠sticos, contexto y visualizaciones.

## Valores P {.bloques}

::::: columns
::: {.column width="50%"}
-   El valor P es una probabilidad que [mide la evidencia en contra de la hip√≥tesis nula]{.hi}. [Entre m√°s bajo este valor, m√°s fuerte ser√° la evidencia en contra]{.underline}.

    -   Se compara contra el nivel de significancia ($\alpha$).

-   Formalmente: un valor P es la probabilidad bajo un modelo estad√≠stico especificado que un resumen estad√≠stico de los datos ser√≠a igual o m√°s extremo que su valor observado.

-   Consulte esta [infograf√≠a](https://stevenggoni.github.io/infografias/Comprendiendo%20el%20valor%20P.pdf){target="_blank"} para ampliar estos conceptos.
:::

::: {.column .img-fit width="50%"}
![Ilustraci√≥n de [Allison Horst](https://allisonhorst.com/allison-horst){target="_blank"}](https://raw.githubusercontent.com/allisonhorst/stats-illustrations/23bb6fe3d5bd6792d85744f8ff18dc7ec22585cd/other-stats-artwork/p_value_mic_hog.jpg)
:::
:::::

## Valores P {.bloques}

-   El valor P [no es el protagonista]{.hi}, es solo una medida estad√≠stica adicional, que [se interpreta en conjunto]{.hi} con las dem√°s medidas.

-   En s√≠ntesis $\alpha$ y valor p est√°n √≠ntimamente relacionados, pues el primero marca el l√≠mite de decisi√≥n con base en el segundo.

-   El nivel de significancia ($\alpha$) se va a usar frecuentemente, este valor hay que escogerlo [cuidadosamente]{.hi} en funci√≥n del contexto, [nunca es una medida gen√©rica]{.hi}.

    -   Como por ejemplo, usar $\alpha=0.05$ para todo sin importar el contexto es un error. Estos valores siempre deben justificarse.

## Valores P {.bloques}

-   Por otro lado, en ocasiones nos vemos tentados a emplear terminolog√≠a incorrecta como:
  
  * Es [MUY significativo]{.hi}, cuando un valor P es muy bajo.

-   Es importante aclarar que la significancia estad√≠stica es un l√≠mite: **solo se puede ser o no ser significativo**.
-   [No puedo ser muy o poco significativo]{.hi}, pues los valores P, como bien se indica en la [infograf√≠a](https://stevenggoni.github.io/infografias/Comprendiendo%20el%20valor%20P.pdf){target="_blank"} no mide el tama√±o de un efecto ni la importancia de un resultado.

## Valores P {.bloques}

::::: columns
::: {.column style="font-size: 0.85em;"}
-   Pi√©nselo de esta manera:
-   ¬øYo soy [‚Äúm√°s tico‚Äù]{.hi} por nacer en San Jos√© que alguien que naci√≥ en Los Chiles?
    -   ¬øVerdad que no?
-   Con base en esta analog√≠a, tampoco puedo ser m√°s significativo con base en un valor P.
    -   As√≠ como cualquier nacimiento dentro de las fonteras costarricenses producen un "tico", cualquier valor por debajo del nivel de siginificancia ($\alpha$) es un resultado significativo, a√∫n cuando ese umbral se supere ampliamente.
-   Lo que puedo estar es m√°s o menos seguro de que ‚Äúsoy tico‚Äù y para ello es relevante [analizar el valor P en conjunto]{.hi} con:
    -   **Evidencias externas** del contexto (dise√±o del estudio, calidad de mediciones, fiabilidad del muestreo).
    -   **Evidencias internas** (otros estad√≠sticos como la estimaci√≥n del intervalo de confianza).
:::

::: {.column .img-fit width="30%"}
![](img/mapa_cr.jpg)
:::
:::::

# Test de $\chi^2$

## Introducci√≥n {.bloques}

-   Se emplea para la bondad de ajuste de [distribuciones discretas]{.hi}.
-   Es un test estad√≠stico que compara las frecuencias observadas con las frecuencias esperadas seg√∫n la distribuci√≥n te√≥rica propuesta.
    -   Tambi√©n conocida como prueba de Pearson.
-   Esta se usa por que es el caso m√°s general y f√°cil de entender, aunque es importante se√±alar que es poco sensible en tama√±os de muestra peque√±os.
-   Tambi√©n es relevante dar a conocer que existen otras pruebas que pueden usarse.

## Procedimiento {.bloques}

:::: columns
::: {.column width="100%"}
-   Se define la prueba de hip√≥tesis

    -   $H_o:$ la distribuci√≥n se ajusta a los datos
    -   $H_i:$ la distribuci√≥n *NO* se ajusta a los datos

-   Se calcula el estad√≠stico $\chi^2$

$$
\chi^2=\sum_{i=1}^{k}\frac{(O_i-E_i)^2}{E_i}
$$

-   Donde $O_i$ es lo observado y $E_i$ es lo esperado.

    -   A partir de ese estad√≠stico $\chi^2$ se puede obtener un valor P que [en conjunto con las rutinas gr√°ficas]{.hi}, y una elecci√≥n adecuada del nivel de significancia ($\alpha$) da origen a las conclusiones acerca de la bondad de ajuste.
:::
::::

## Aclaraciones {.bloques}

-   Esta prueba [tambi√©n puede usarse con datos continuos]{.hi}, pero no es ‚Äú*nativa*‚Äù para este tipo de datos, por lo que dichos datos deben ‚Äú*discretizarse*‚Äù en clases (como los de un histograma) y luego comparar las frecuencias observadas en cada clase.
-   Pero no se recomienda usarla en estos casos por la falta de potencia, son mejores las opciones que veremos adelante.

## Ejemplo 01 {.bloques}

:::::: {.columns}

::: {.column width="50%"}

* Se realiza el lanzamiento de un dado en 120 ocasiones. Se anotan los resultados.
* ¬øLos datos est√°n balanceados? Es decir, ¬øse sigue una distribuci√≥n uniforme discreta? 
  * Responda con $\alpha=0.05$
* En este [Excel](https://stevenggoni.github.io/clases/data/II-1123_02_Ejemplos y ejercicios resueltos.xlsx){target="_blank"} puede encontrar los datos sin procesar, as√≠ como los ejemplos resueltos.

:::

::: {.column width="50%"}

```{r}

ejemplo_01 <- openxlsx::read.xlsx("data/II-1123_02_Ejemplos y ejercicios resueltos.xlsx", 
                                  sheet = "Ejemplo 01", 
                                  cols = 2)

ejemplo_01 %>% 
  dplyr::count(Lanzamiento, name = "Conteo (Observado)") %>% 
  knitr::kable(format = "html") %>%
  kableExtra::kable_styling()

```


:::

::::::

## Ejemplo 01 {.bloques}

:::::: {.columns}

::: {.column width="50%"}

* El primer paso, antes de buscar obtener un valor P a como de lugar, es realizar las rutinas gr√°ficas.

  * Como este conjunto de datos es discreto, lo que conviene es realizar un gr√°fico de barras. 

* El gr√°fico mostrado a la derecha, ¬øparece ser una uniforme discreta? 
  * Aunque pueda generarle dudas, razonablemente parece seguir una uniforme. Esta visualizaci√≥n es importante, porque inmediatamente le hace ver que el valor de 3 dificilmente alcanza el valor esperado y que el de 6 lo supera con creces.  
  * No obstante, no se puede ser m√°s estricto de la cuenta. 

:::

::: {.column width="50%"}

```{r}

gej1 <- ejemplo_01 %>% 
  dplyr::count(Lanzamiento) %>% 
  dplyr::mutate(Esperado = (1/6)*120) %>% 
  ggplot(aes(x = Lanzamiento, y = n)) +
  geom_col(aes(fill = "Observado")) +
  geom_point(aes(y = Esperado, fill = "Esperado"), 
             color = "#C18A00", size = 3)+
  scale_fill_manual(values = c("Observado" = "#263247", 
                               "Esperado" = "#C18A00")) +
  labs(x = "Valor del dado",
       y =  "Frecuencia", 
       fill = "") +
  theme_bw()

plotly::ggplotly(gej1, height = 650, width = 850) %>% 
  plotly::layout(paper_bgcolor = "#F1F5F5",
                 plot_bgcolor  = "#F1F5F5",
                 font = list(size = 30),
                 xaxis = list(
                   title = list( font = list(size = 30)),
                   tickfont = list(size = 25)),
                 yaxis = list(title = list(font = list(size = 30)),
                              tickfont = list(size = 25)),
                 legend = list(title = list(font = list(size = 25)),
                               font = list(size = 20),
                               bgcolor = "#F1F5F5"))

```


:::

::::::

## Ejemplo 01 {.bloques}

:::::: {.columns}

::: {.column}

```{r}

ejemplo_01 %>% 
  dplyr::count(Dado = Lanzamiento, name = "Observado \\((O_i\\))") %>% 
  dplyr::mutate("P(Esperada)" = (1/6),
                "Esperado \\((E_i\\))" = (1/6)*120, 
                "\\(\\frac{(O_i-E_i)^2}{E_i}\\)" = 
                  (`Observado \\((O_i\\))` - `Esperado \\((E_i\\))`)^2/`Esperado \\((E_i\\))`) %>% 
  janitor::adorn_totals() %>% 
  dplyr::mutate(across(2:5, ~ round(.x, 3))) %>% 
  knitr::kable(format = "html", escape = FALSE) %>%
  kableExtra::kable_styling()  
  

```


:::

::::::

## Ejemplo 01 {.bloques}

:::::: {.columns}

::: {.column width="50%"}

* Obtenga el valor P a partir del estad√≠stico $\chi^2$

* En Excel hay dos formas de hacerlo (f√≥rmulas en *ingl√©s*)

  * Forma corta: CHISQ.TEST($O_i$, $E_i$)
    
  * Forma larga: 1-CHISQ.DIST($\chi^2$, $n-1$, TRUE)

* En R `chisq.test(x = c(21, 21, 15, 21, 18, 24), p = rep(1/6, 6))`

:::

::: {.column width="50%"}

* $\chi^2=2.4$
* Valor P (forma corta) = $0.7915$
* Valor P (forma larga) = $0.7915$
* Significancia = $0.05$

* No hay evidencia suficiente para rechazar la hip√≥tesis nula de que el dado se comporta como una distribuci√≥n uniforme discreta de probabilidad $\frac{1}{6}$, dado que $p>\alpha$, aunado a lo mostrado en el gr√°fico anterior.


:::

::::::

## Ejercicio 01 {.bloques}

* Se ha recolectado 400 observaciones sobre la cantidad de personas que que se reciben cada minuto en una estaci√≥n de tren de la capital. 

* Por la naturaleza de este proceso, se sospecha que estos datos son una variable aleatorio que sigue la [distribuci√≥n de Poisson]{.hi}. 

* En [Excel](https://stevenggoni.github.io/clases/data/II-1123_02_Ejemplos y ejercicios resueltos.xlsx) se le hace entrega de los datos y del ejercicio resuelto, procure realizar este ejercicio por su cuenta y utilice el ejercicio resuelto solo en caso de dudas.

## Ejercicio 01 {.bloques}

* Determine el par√°metro de la distribuci√≥n. Como el enunciado deja en claro, esta es una Poisson, por lo tanto, el par√°metro es $\lambda$.

  * Como es una muestra, el par√°metro se estima. En una Poisson se sabe que $E(x)=\lambda$.
  * $\lambda=4.575$
  
* Realice una rutina gr√°fica. 
  * Recomendaci√≥n: $E_i$ debe sumar 400 (es decir, las probabilidades siempre deben suma 1), por lo que quiz√° deba agregar datos en cero, por ejemplo: 
    * 15 personas observadas 0 veces, esperadas 0.03.
    * Salvo el c√°lculo de $\lambda$, resuelva con dos decimales. 
    
## Ejercicio 01 {.bloques}

```{r}

ejercio_01 <- openxlsx::read.xlsx("data/II-1123_02_Ejemplos y ejercicios resueltos.xlsx",
                                  sheet = "Ejercicio 01")

gej1 <- ejercio_01 %>% 
  dplyr::count(Llegadas) %>% 
  dplyr::mutate(Masa = dpois(0:11, lambda = 4.575)) %>% 
  ggplot(aes(x = Llegadas, y = n/400)) +
  geom_col(fill = "#263247") +
  geom_point(aes(y = Masa), color = "#C18A00", size = 4) +
  labs(y = "Masa") +
  theme_bw()

plotly::ggplotly(gej1, height = 780, width = 1900) %>% 
  plotly::layout(paper_bgcolor = "#F1F5F5",
                 plot_bgcolor  = "#F1F5F5",
                 font = list(size = 30),
                 xaxis = list(
                   title = list( font = list(size = 30)),
                   tickfont = list(size = 25)),
                 yaxis = list(title = list(font = list(size = 30)),
                              tickfont = list(size = 25)))


```

    
## Ejercicio 01 {.bloques}

:::::: {.columns}

::: {.column width="50%"}

* Por ejemplo, en este caso las probabilidades no suman 1, ni los valores esperados 400, por lo que debemos agregar m√°s valores con 0 observaciones. 

* No obstante, [Cochran]( https://doi.org/10.1214/aoms/1177729380){target="_blank"} y otros autores mencionan que se debe cumplir una regla b√°sica: 

  * Todos los $E_i \ge 3$ o $E_i \ge 3$

* Por lo que estos valores deben agregarse. Para efectos de este curso usaremos $E_i \ge 5$.

:::

::: {.column width="50%" style="font-size: 0.68em;"}

```{r}

ejercio_01 %>% 
  dplyr::count(Llegadas, name = "Frecuencia") %>% 
  dplyr::mutate(PEi = dpois(0:11, lambda = 4.575), 
                Ei = PEi*400, 
                chi = (Frecuencia - Ei)^2/Ei) %>% 
  janitor::adorn_totals() %>% 
  dplyr::mutate(across(2:5, ~round(.x, 3))) %>% 
  setNames(c("Llegadas", "\\(O_i\\)", 
             "P(\\(E_i\\))", "\\(E_i\\)",
             "\\(\\frac{(O_i-E_i)^2}{E_i}\\)")) %>% 
  knitr::kable(format = "html", escape = FALSE) %>%
  kableExtra::kable_styling()  

```

:::


::::::


## Ejercicio 01 {.bloques}

:::::: {.columns}

::: {.column style="font-size: 0.53em;"}

```{r}

ejercio_01 %>% 
  dplyr::count(Llegadas, name = "Frecuencia") %>% 
  dplyr::add_row(Llegadas = 12:16, Frecuencia = rep(0, 5)) %>% 
  dplyr::mutate(PEi = dpois(0:16, lambda = 4.575), 
                Ei = PEi*400, 
                chi = (Frecuencia - Ei)^2/Ei) %>% 
  janitor::adorn_totals() %>%
  dplyr::mutate(across(3:5, ~round(.x, 4))) %>% 
  setNames(c("Llegadas", "\\(O_i\\)", 
             "P(\\(E_i\\))", "\\(E_i\\)",
             "\\(\\frac{(O_i-E_i)^2}{E_i}\\)")) %>% 
  knitr::kable(format = "html", escape = FALSE) %>%
  kableExtra::kable_styling() 

```


:::

::: {.column style="font-size: 0.61em;"}

En la primera tabla se obtiene un valor de $\chi^2=9.24$ con un valor P = $0.9031$. No obstante, no se cumple la regla de que $E_i\ge5$.

Por tanto, procedemos a agrupar valores que incumplen la regla con el m√°s cercano posible, por ejemplo $E_0+E_1 = 3 + 15 = 18$. Obteniendo un valor P = $0.6264$.

```{r}

p <- c(0.0574576179173541, 0.107858641616271, 
       0.164484428464813, 0.18812906505663, 
       0.172138094526816, 0.131255297076698, 
       0.0857847120179845, 0.0490581321852849,
       0.0249378838608532, 0.0188896172863315)

p <- p/sum(p)

data.frame(Llegadas = c("0-1", 2, 3, 4, 5, 6, 7, 8, 9, ">=10"), 
           Frecuencia = c(18, 39, 69, 82, 68, 61, 33, 16, 5, 9),
           PEi = p) %>% 
  dplyr::mutate(Ei = PEi*400, 
                chi = (Frecuencia - Ei)^2/Ei) %>% 
  janitor::adorn_totals() %>%
  dplyr::mutate(across(3:5, ~round(.x, 4))) %>% 
  setNames(c("Llegadas", "\\(O_i\\)", 
             "P(\\(E_i\\))", "\\(E_i\\)",
             "\\(\\frac{(O_i-E_i)^2}{E_i}\\)")) %>% 
  knitr::kable(format = "html", escape = FALSE) %>%
  kableExtra::kable_styling() 


```


:::

::::::

## Sensibilidad de $\chi^2$ {.bloques}

* El c√°lculo estad√≠stico de $\chi^2$ y su comparaci√≥n con un valor cr√≠tico de la distribuci√≥n $\chi^2$ permite al investigador evaluar si los recuentos de celdas observados son significativamente diferentes de los recuentos de celdas esperados.
* Debido a la forma en que se calcula el valor de $\chi^2$, es [extremadamente sensible al tama√±o de la muestra]{.hi}: 
  
  * Cuando el tama√±o de la muestra es demasiado grande (~500), casi cualquier peque√±a diferencia parecer√° estad√≠sticamente significativa. Por tanto, debe analizarse con m√°s cuidado, utilizando otras evidencias adem√°s del valor P. 
  
# Pruebas de normalidad {.bloques}

## Introducci√≥n {.bloques}

* Nos vamos a adentrar en el universo de las pruebas de normalidad, pero la idea es hacerlo est√°ndo preparados. 

* Por lo general, desarrollar pruebas de normalidad de forma manual (con apoyo de software como Excel), puede ser muy laborioso. 

* Por tanto, este abordaje ser√° basado en el uso de software estad√≠stico (`R`, `Minitab`, entre otros).

## Introducci√≥n {.bloques}

* La idea b√°sica que se quiere desarrollar es que las pruebas de normalidad NO SON INTERCAMBIABLES sin m√°s: 
  
  * No tienen la misma [sensibilidad]{.hi}
  * Su [potencia]{.hi} var√≠a con el tama√±o de muestra
  * Los [contextos]{.hi} en los que se aplican son diversos

* Pero todas parten de la misma hip√≥tesis: 
  * $H_o: \text{los datos siguen una distribuci√≥n normal}$

## Introducci√≥n {.bloques}
  
* En esta sesi√≥n de trabajo vamos a aprender qu√© caracter√≠sticas tienen las pruebas de normalidad, para que pueda escogerlas m√°s adelante. 
* Por *tradici√≥n* se suele usar `Minitab` para hacerlo, pero se nombraran otras que no est√°n presentes en este software, pues no es el √∫nico que existe ni el que se usa en ambientes fabriles. 

## Caracter√≠sticas {.bloques}

* Un conjunto de datos puede [no seguir la distribuci√≥n normal]{.hi} por al menos dos grandes motivos: 

  * La distribuci√≥n es asim√©trica
  * Las colas son pesadas

* Por lo que la selecci√≥n de una prueba [debe ser concordante con el tipo de desviaci√≥n que nos preocupe]{.hi}. Ya las pruebas, por lo general, suelen darle m√°s importancia a uno de los dos motivos anteriores

## Por ejemplo {.bloques}

* Un an√°lisis de regresi√≥n (*tema que se atiende luego en el curso*) es robusto a desviaciones ligeras de la normalidad, por lo que conviene utilizar una prueba que no penalice en exceso dichas desviaciones. 

* Por otro lado, los an√°lisis de capacidad (*tema de ingenier√≠a de calidad*) son muy sensibles a desviaciones en el supuesto de normalidad por las colas, por lo que conviene utilizar una prueba de normalidad que sea apropiada para este contexto. 

  * Desviaciones en la normalidad a causa de las colas pesadas incrementa la probabilidad de valores extremos y aumenta la estimaci√≥n de la desviaci√≥n est√°ndar

* En resumen, [es el contexto]{.hi} el que dicta la adecuaci√≥n de las pruebas de normalidad usadas. 

## Pruebas de normalidad {.bloques}

:::::: {.columns}

::: {.column width ="50%"}

```{r}

# Tama√±o de muestra 100 -------------------------------------------------------

like_ESM_reg <- function(a, g, l, m, beta0, beta1, beta2){
  veros <- ESM(x = y,
               alpha = exp(a),
               beta = exp(beta0 + beta1 * X1 + beta2 * X2),
               gamma = exp(g),
               lambda = exp(l),
               mu = m)
  -sum(log(veros)) %>%
    suppressWarnings()
}

ESM <- function(x, alpha, beta, gamma, lambda, mu){
  
  
  part_I <- (lambda*alpha)/(gamma*beta^(1/gamma))
  
  part_II <- (x - mu)^((1/gamma)-1)
  
  part_III <- (1+((x-mu)/beta)^(1/gamma))^(alpha-1)
  
  part_IV <- exp(-lambda*(1+((x-mu)/beta)^(1/gamma))^(alpha))
  
  ESM <- part_I * part_II * part_III * part_IV
  
  return(ESM)
  
}

set.seed(124)

N <- 100

X1 <- runif(N, 0, 1)
X2 <- rbinom(N, 1, 0.5)

escala <- exp(4 - 0.5*X1 - 0.5 * X2)

y <- VGAM::rsinmad(N, scale = escala, shape1.a = 5, shape3.q = 2)

reg_100 <- stats4::mle(minuslogl = like_ESM_reg, 
                       start = list(a = 2,
                                    g = 3, 
                                    l = -2,
                                    beta1 = -0.5,
                                    beta2 = -0.5),
                       fixed = list(beta0 = 4, m = 0))@fullcoef

coeficientes_regresion <- c(reg_100[5], # intercepto
                            reg_100[6], # X1
                            reg_100[7]) # X2

par_aux <- c(reg_100[1] %>% exp(), # alpha
             reg_100[2] %>% exp(), # gamma
             reg_100[3] %>% exp()) # lambda

residuos <- data.frame(X1 =  X1, X2 = X2, y = y) %>% 
  dplyr::mutate(y_hat_lineal = cbind(1, X1, X2) %*% coeficientes_regresion,
                y_hat = exp(y_hat_lineal),
                residuos_resp = y - y_hat,
                signo = if_else(residuos_resp > 0, 1, -1),
                log_vero_obs = log(ESM(y, par_aux[1], y_hat, 
                                       par_aux[2], par_aux[3], 0)),
                log_vero_sat = log(ESM(y, par_aux[1], y, 
                                       par_aux[2], par_aux[3], 0)), 
                residuos_dev = signo*sqrt(2*(log_vero_sat - log_vero_obs)),
                residuos_dev = if_else(is.nan(residuos_dev), 
                                       0, residuos_dev)) %>% 
  suppressWarnings()

texto_label <- paste(
  "Valor P (SW) =",
  scales::pvalue(shapiro.test(residuos$residuos_dev)$p.value),
  "<br>",
  "Valor P (KS) =",
  scales::pvalue(nortest::lillie.test(residuos$residuos_dev)$p.value))

  # QQ plot

p1 <- residuos %>%
  ggplot2::ggplot(aes(sample = residuos_dev)) +
  stat_qq () +
  stat_qq_line(color = "#556070") +
  labs(x = "Datos",
       y = "Cuantiles") +
  theme_bw()

# histograma

p2 <-  residuos %>%
  ggplot2::ggplot(aes(residuos_dev)) +
  geom_histogram(bins = 7, color =  "#C18A00",
                 fill = "#263247") +
  labs(x = "Datos",
       y = "Frecuencia") +
  theme_bw()

# ---- QQ plot interactivo  ----
p1_plotly <- ggplotly(p1, source = "qq")

p1_plotly <- p1_plotly %>%
  layout(annotations = list(x = -1.2,
                            y = 1.6,
                            text = texto_label,
                            showarrow = FALSE,
                            bgcolor = "white",
                            bordercolor = "black"))

# ---- Histograma interactivo ----

p2_plotly <- ggplotly(p2, source = "hist")

fig <- subplot(p1_plotly,
               p2_plotly,
               nrows = 2,
               shareX = FALSE,
               shareY = FALSE,
               which_layout = 1)

# ---- Ahora s√≠ aplicar layout global y tama√±o ----
fig <- fig %>%
  layout(#height = 780,
         #width  = 850,
         paper_bgcolor = "#F1F5F5",
         plot_bgcolor  = "#F1F5F5",
         font = list(size = 30),
         xaxis  = list(title = list(font = list(size = 30)),
                       tickfont = list(size = 25)),
         yaxis  = list(title = list(font = list(size = 30)),
                       tickfont = list(size = 25)),
         xaxis2 = list(title = list(font = list(size = 30)),
                       tickfont = list(size = 25)),
         yaxis2 = list(title = list(font = list(size = 30)),
                       tickfont = list(size = 25)))

fig$height <- 700
fig$width  <- 850

fig
```

:::

::: {.column width ="50%"}

* ¬øPor qu√© en este caso la prueba de Shapiro ‚Äì Wilk (SW), con un 95 % de confianza, no rechaza la hip√≥tesis nula, mientras que Kolmog√≥rov-Smirnov (KS) si lo hace?

* ¬øCu√°l prueba escojo?
  * Discuta con compa√±er@s y persona docente. 


:::

::::::

## Pruebas de normalidad {.bloques}

* ¬øQu√© sucede en la pr√°ctica? Y que no necesariamente es una buena pr√°ctica.

* Las personas realizan varias pruebas de normalidad y se reportan la que les da bien seg√∫n sus objetivos (rechazar o no rechazar).

* Esto no es [√©ticamente correcto]{.hi} y por ello se les insta a comprender cuando funciona mejor cada prueba de normalidad. 

## Anderson - Darling (AD) {.bloques}

* Tiene una sensibilidad especial en las colas de la distribuci√≥n y es justo por este motivo que es la primera opci√≥n en Minitab y otros software, pues desviaciones en las colas genera problemas en la estimaci√≥n de √≠ndices de calidad (tema de ingenier√≠a de calidad abordado en otros cursos).
* Su principal limitaci√≥n deviene en que, cuando ùëõ es grande tiende a sobre ‚Äì rechazar la hip√≥tesis nula. 

## Shapiro - Wilk (SW) {.bloques}

* Si bien no est√° presente en software como `Minitab` de forma expl√≠cita, es necesario explicarla. 
* Es una prueba que se centra en las diferencias de forma global (asimetr√≠a y colas).
* Su limitaci√≥n se basa en que con $n$ muy grande puede rechazar $H_o$ por desviaciones irrelevantes. 

## Ryan - Joiner (RJ) {.bloques}

* Es similar a SW, pues se centra en desviaciones generales. Es por este motivo que suele preferirse en muestras ‚Äúpeque√±as‚Äù.
* Posee las mismas limitaciones que SW. 
* La l√≥gica del estad√≠stico est√° m√°s centrada en la alineaci√≥n global, donde indefectiblemente la mayor contribuci√≥n proviene del centro de la distribuci√≥n. 
* Es decir, las colas si influyen, pero no tanto como en AD, porque su efecto est√° diluido. 

## Kolmog√≥rov - Smirnov (KS) {.bloques}

* Est√° centrado en la desviaci√≥n general en la forma de la distribuci√≥n. Requiere de par√°metros conocidos, por lo que la versi√≥n de Minitab es menos potente, pues trabaja con estimaciones ($\bar{x}$ en lugar de $\mu$)).
* Es m√°s sensible a las colas que RJ y SW, pero menos que AD.
* KS no es por lo general la primera opci√≥n pues en colas pesadas gana AD y en el centrado/asimetr√≠a de la distribuci√≥n gana RJ y SW.

## Ejemplo 02 {.bloques}

:::::: {.columns}

::: {.column width="50%"}

En [Excel](https://stevenggoni.github.io/clases/data/II-1123_02_Ejemplos y ejercicios resueltos.xlsx){target="_blank"}, en la pesta√±a con este mismo nombre, puede encontrar un conjunto de datos. 
Realice un histograma de los datos. 
Con un 99 % de confianza, realice al menos tres pruebas de normalidad o con las que cuente el software que est√© usando. 

:::

::: {.column width="50%"}

```{r}

ejemplo_02 <- openxlsx::read.xlsx("data/II-1123_02_Ejemplos y ejercicios resueltos.xlsx", 
                                  sheet = "Ejemplo 02")

gej02 <- ejemplo_02 %>% 
  ggplot(aes(Normalidad)) +
  geom_histogram(bins = round(1+log2(140)), 
                 fill = "#263247", 
                 color = "#C18A00") +
  theme_bw()

plotly::ggplotly(gej02, width = 850, height = 500) %>% 
    plotly::layout(paper_bgcolor = "#F1F5F5",
                 plot_bgcolor  = "#F1F5F5",
                 font = list(size = 25),
                 xaxis = list(
                   title = list( font = list(size = 25)),
                   tickfont = list(size = 22)),
                 yaxis = list(title = list(font = list(size = 25)),
                              tickfont = list(size = 22)))

```


:::

::::::

## Ejemplo 02 {.bloques}

:::::: {.columns}

::: {.column width="50%"}

* Con base en el an√°lisis gr√°fico y los valores p obtenidos.

* Prepare un esquema en el que responda al ¬øpor qu√© con una prueba se rechaza y con las otras no?

:::


::: {.column width="50%"} 

```{r}

data.frame(Prueba =  c("AD", "KS", "RJ"), 
           "Valor p" = c(0.009, 0.013, 0.022)) %>% 
  knitr::kable(format = "html") %>%
  kableExtra::kable_styling()

```

:::

::::::

## Conclusiones y recomendaciones {.bloques}

* Si el tama√±o de muestra es peque√±o, no conviene penalizar fuertemente las colas, pues un solo valor, que puede ser ‚Äúmala suerte‚Äù puede tener mucho peso en la decisi√≥n sobre la normalidad. 

* Si $n$ es muy grande, conviene interpretar los valores P con cautela, pues son valores del tipo ‚Äúcaja negra‚Äù. Es decir, preste muchas m√°s atenci√≥n a las rutinas gr√°ficas. 

* Conviene siempre realizar el an√°lisis gr√°fico (rutinas gr√°ficas) primero, antes de aplicar una prueba formal de normalidad. 

* Las conclusiones finales sobre la normalidad de un conjunto de datos [no pueden]{.hi} estar basadas solo en un valor P. 

# Otras rutinas de identificaci√≥n de distribuciones {.bloques}

## Identificaci√≥n de distribuciones {.bloques}

* Muchos softwares estad√≠sticos (libres o comerciales) tienen incluidas rutinas de identificaci√≥n de distribuciones que funcionan de forma que prueban muchas distribuciones a la vez.

* Esto es importante, para decidir sobre el tipo de modelo y an√°lisis estad√≠stico a emplear. 

* N√≥tese que las distribuciones tienen sus propias caracter√≠sticas, no se deben usar indiscriminadamente. Las pruebas estad√≠sticas no pueden supeditar la teor√≠a y el sentido com√∫n. 

## Identificaci√≥n de distribuciones {.bloques}

* Es decir, que un identificador de distribuciones puede decir que mis datos siguen alguna distribuci√≥n y esto no tener sentido alguno en la pr√°ctica. 

* Estudie si la distribuci√≥n que le toc√≥ es adecuada o si hay otra, no tan buena, pero que tiene m√°s sentido te√≥rico pr√°ctico. 

## Ejemplo 03 {.bloques}

* Utilice los datos del ejemplo 02 y encuentre mediante un identificador de distribuciones (puede ser en R, Python, Minitab, etc), qu√© distribuci√≥n se ajusta mejor a los datos. Use $\alpha = 0.01$.
* Recuerde que: 
  * Las rutinas gr√°ficas ya las hizo, por eso no se repiten, pero siempre deben hacerse. 
  * ¬øVa a probar todas las distribuciones? Si no conoce alguna, puede que sea conveniente que la estudie de forma individual.

## Ejemplo 03 {.bloques}

:::::: {.columns}

::: {.column width="50%"}

* El concepto de transformaci√≥n no es abarcado a√∫n. Por lo que de obtenerlos, puede ignorarlos. 

* En este y otros ejercicios [puede]{.hi} obtener valores diferentes a los aqu√≠ mostrados, como consecuencia de los algor√≠tmos empleados en los c√°lculos. 
  * Para este ejercicio, se est√° usando la prueba de KS, Minitab suele usar AD.

* N√≥tese como este conjunto de datos se ajusta a 4 distribuciones distintas. ¬øCu√°l escojo? Depender√° del contexto y conveniencia.  

:::

::: {.column width="50%"}

### Resultados de un identificador de distribuciones

```{r}

# probamos varias distribuciones

distribuciones <- c("weibull", "lnorm", "exp", # agregar m√°s si es conveniente
  "gamma", "unif", "logis", "norm") %>% 
  purrr::map(function(x){
    fitdistrplus::fitdist(ejemplo_02$Normalidad, x)
    })

bondad_ajuste <- fitdistrplus::gofstat(distribuciones)

data.frame(Distribuci√≥n = c("Weibull", "Lognormal", "Exponencial",
                            "Gamma", "Uniforme", "Log√≠stica", "Normal"), 
           "Valor p" = round(bondad_ajuste$chisqpvalue,3)) %>% 
  tibble::remove_rownames() %>% 
  knitr::kable(format = "html") %>%
  kableExtra::kable_styling()
```


:::

::::::

## Bibliograf√≠a {.bloques}

:::: columns
::: {.column width="100%" style="font-size: 1.2em;"}

* Las fuentes de esta sesi√≥n provienen de diferentes libros de texto, cuya menci√≥n no es necesaria porque ahondan en exceso en conceptos que no son pertinentes al alcance de este curso.


:::
::::

## Pruebas de bondad de ajuste para distribuciones <br> II-1123 Estad√≠stica para Ingenier√≠a Industrial II {.center}

### Gracias por su atenci√≥n <br> Steven Garc√≠a Go√±i<br>[steven.garciagoni\@ucr.ac.cr](mailto:steven.garciagoni@ucr.ac.cr) {.subtitle}

### Dudas o correcciones requeridas pueden solicitarse al correo